{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Classification\n",
    "Simo Hyttinen<br>\n",
    "Student #1503565<br>\n",
    "Helsinki Metropolia University of Applied Sciences<br>\n",
    "Last edited: <i>31.01.2018</i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "The objective of this assignment is to create a program which can preprocess a dataset and then use that dataset to train a dense neural network to predict whether a person has heart disease or not, based on 13 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing a preprocessed dataset\n",
    "The following imports a preprocessed dataset and sets the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs',\n",
    "                  'restecg', 'thalach', 'exang', 'oldpeak',\n",
    "                  'slope', 'ca', 'thal', 'num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prep_csv(filename):\n",
    "    df_ret = pd.read_csv(filename, na_values='?')\n",
    "    df_ret.columns = colnames\n",
    "    return  df_ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and preprocessing a raw dataset\n",
    "This imports a set of raw data and parses it into intelligible entries.<br><br>\n",
    "Each entry in the raw dataset is divided to 10 rows with 7-8 columns each (1st row of each entry has no 8th column for some reason). I checked the correct positions of each of the 14 values from the dataset documentation and picked the right values to pull from which row and which column. These are stored in a temporary dataframe. The entries are separated from each other by calculating the modulo 10 of the row index. Depending on the modulus, different actions are taken. From 0-8 values are stored in the temp dataframe. When the modulus is 9, it means the entry is at its end and the temp dataframe is appended to the processed dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_csv(filename):\n",
    "    testcols = [\"col1\", \"col2\", \"col3\", \"col4\", \"col5\", \"col6\", \"col7\", 'col8']\n",
    "    df_raw = pd.read_csv(filename, sep=' ', names=testcols)\n",
    "    df_ret = pd.DataFrame(index=[0], columns=colnames)\n",
    "    df_temp = pd.DataFrame(index=[0], columns=colnames)\n",
    "    \n",
    "    for i, row in df_raw.iterrows():\n",
    "        m = i % 10\n",
    "        if m == 0:\n",
    "            df_temp.iloc[0]['age'] = float(row['col3'])\n",
    "            df_temp.iloc[0]['sex'] = int(row['col4'])\n",
    "        elif m == 1:\n",
    "            df_temp.iloc[0]['cp'] = int(row['col2'])\n",
    "            df_temp.iloc[0]['trestbps'] = float(row['col3'])\n",
    "            df_temp.iloc[0]['chol'] = float(row['col5'])\n",
    "        elif m == 2:\n",
    "            df_temp.iloc[0]['fbs'] = float(row['col1'])\n",
    "            df_temp.iloc[0]['restecg'] = float(row['col4'])\n",
    "        elif m == 4:\n",
    "            df_temp.iloc[0]['thalach'] = float(row['col1'])\n",
    "            df_temp.iloc[0]['exang'] = float(row['col7'])\n",
    "        elif m == 5:\n",
    "            df_temp.iloc[0]['oldpeak'] = float(row['col1'])\n",
    "            df_temp.iloc[0]['slope'] = float(row['col2'])\n",
    "            df_temp.iloc[0]['ca'] = float(row['col5'])\n",
    "        elif m == 6:\n",
    "             df_temp.iloc[0]['thal'] = float(row['col4'])\n",
    "        elif m == 7:\n",
    "            df_temp.iloc[0]['num'] = int(row['col3'])\n",
    "        elif m == 9:\n",
    "            for ix in range(len(df_temp.columns)):\n",
    "                if df_temp.iloc[0][ix] == -9:\n",
    "                    df_temp.iloc[0][ix] = nan\n",
    "            df_ret = df_ret.append(df_temp, ignore_index=True)\n",
    "\n",
    "    df_ret.drop(df_ret.index[0], inplace=True)\n",
    "    return df_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the different datasets are combined into one big dataset. The already preprocessed version of the Cleveland data is used because the raw data file is corrupted. <i>New.data</i> is not used because it seems to have a slightly different formatting compared to the other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in the dataset: 919\n"
     ]
    }
   ],
   "source": [
    "df_hu = parse_raw_csv(\"data/hungarian.data\")\n",
    "df_sw = parse_raw_csv(\"data/switzerland.data\")\n",
    "df_cl = format_prep_csv(\"data/processed.cleveland.data\")\n",
    "df_lbc = parse_raw_csv(\"data/long-beach-va.data\")\n",
    "df = pd.concat([df_hu, df_sw], ignore_index=True).append(df_cl, ignore_index=True).append(df_lbc, ignore_index=True)\n",
    "print(\"Number of entries in the dataset: \" + str(len(df.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the data\n",
    "The contains 14 variables that describe the person in the entry:\n",
    "- Sex\n",
    "- Age\n",
    "- Chest pain type\n",
    "    - 1: Typical angina\n",
    "    - 2: Atypical angina\n",
    "    - 3: Non-anginal pain\n",
    "    - 4: Asymptomatic\n",
    "- Resting blood pressure (mm/Hg) on admission\n",
    "- Serum cholesterol (mg/dl)\n",
    "- Fasting blood sugar\n",
    "    - 1: Over 120mg/dl\n",
    "    - 0: Under 120mg/dl\n",
    "- Resting electrocardiographic results\n",
    "    - 0: Normal\n",
    "    - 1: ST-T wave abnormality\n",
    "    - 2: Probable or definite left ventricular hypertrophy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
